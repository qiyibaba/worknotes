# 普通事务优化

SQL 的执行计划分为Local 、Remote 、Distribute。

- Local 表示当前语句所涉及的分区 Leader 与 Session 所在的机器相同；
- Remote表示当前语句所涉及的分区 Leader 与 Sesison 所在的机器不同；
- Distribute 计划涉及多个分区，多个分区可能在一台机器也可能在多台机器

对于事务的性能而言，优先使用单机事务，其次才是分布式事务

## Remote计划

> remote计划占比4%,由于从回放中抓取的数据，不涉及多条语句，所以remote计划的占比比真实情况要高

remote计划产生的原因主要有3种：

1. 由于OBProxy路由错误，导致请求发送给了非leader节点

2. XA事务的随机路由，导致请求发送给了非leader节点

3. 由于事务中存在多条语句，3.2版本中事务都是由第一条语句中所涉及的节点进行处理，如果后续的语句的leader不跟第一条leader在一起，就会出现remote执行计划

对主键查询的local计划和remote计划进行测试

测试语句：

```plsql
SELECT THIS_.INV_ITEM_ID AS INV_ITEM_ID1_100_0_, THIS_.BE_ID AS BE_ID2_100_0_, THIS_.CREATE_TIME AS CREATE_TIME3_100_0_, THIS_.GOODS_CODE AS GOODS_CODE4_100_0_, THIS_.GOODS_FEE AS GOODS_FEE5_100_0_, THIS_.GOODS_NAME AS GOODS_NAME6_100_0_, THIS_.GOODS_QUANTITY AS GOODS_QUANTITY7_100_0_, THIS_.GOODS_UNIT AS GOODS_UNIT8_100_0_, THIS_.GOODS_UNIT_PRICE AS GOODS_UNIT_PRICE9_100_0_, THIS_.INV_OID AS INV_OID10_100_0_, THIS_.STANDARD AS STANDARD11_100_0_, THIS_.TAX AS TAX12_100_0_, THIS_.TAX_FEE AS TAX_FEE13_100_0_ FROM INV_TAX_INVOICE_ITEM THIS_ WHERE (THIS_.INV_ITEM_ID=100000000061036 AND THIS_.BE_ID=23)
```

对该表进行了2次压测：

![](/Users/qiyibaba/gitbook/image/2022-10-28-14-55-41-image.png)

从测试结果看，local计划的主键查询平均执行耗时为100us，而remote计划的主键查询平均耗时为355us，性能差距约为255us，性能差距分为2部分：

1. remote需要获取2次执行计划，local只需要获取一次执行计划，获取执行计划的时间有差异

2. remote存在2次节点间的RPC通信，一次被统计到是查询结果的传输，一次未被记录是SQL的发送
   
   ```
   -单机的响应时间= get_plan_time + execute_time
   -远程的响应时间= get_plan_time * 2 + execute_time + (1 + 返回包大小/64K) * 网络时延
   ```

所以我们推荐将remote计划改造成local计划

改造方式：

1. 普通事务需要保证业务第一条语句可以精准路由，不使用一些类似“select 1”的无意义的语句作为第一条语句
2. 尽量使用普通事务，由于当前版本中不支持XA精准路由，所以建议去除非必要的XA计划，同时OceanBase已经计划支持XA事务
3. 由于事务中存在多条语句的leader不在一起导致
   1. 将可以汇聚的业务进行租户拆分，使用小租户
   2. 对于无法拆分的业务，需要考虑进行表级的leader汇聚，汇聚方式有tablegroup和表级聚合能力的支持，表级聚合在4.2支持

## Distribute计划

Distribute计划主要考虑2种场景，1种是多表的关联查询，1种是单表的多分区扫描：

### 多表的关联查询

> 多表关联计划占比2.4%

测试语句为：

```plsql
SELECT A.ADDR_1, A.ADDR_10, A.ADDR_11, A.ADDR_12, A.ADDR_13, A.ADDR_14, A.ADDR_15, A.ADDR_2, A.ADDR_3, A.ADDR_4, A.ADDR_5, A.ADDR_6, A.ADDR_7, A.ADDR_8, A.ADDR_9, A.ADDR_ID, A.REGION_ID, A.ADDR_TEMP_ID, A.ADDR_TYPE, A.CREATE_DEPT_ID, A.CREATE_PROLE_ID, A.CREATE_PROLE_TYPE, A.MODIFY_DEPT_ID, A.MODIFY_PROLE_ID, A.MODIFY_PROLE_TYPE, A.PARTY_ID, A.PARTY_TYPE, A.POSTAL_CODE, A.US_ADDR, A.CREATE_TIME, A.EFF_DATE, A.EXP_DATE, A.MODIFY_TIME, A.DISTRICT_ID, A.DISTRICT_NAME, A.BE_ID, B.ADDR_REF_ENTITY_ID, B.ADDR_REF_ID, B.ADDR_REF_PURPOSE_ID, B.PREFERENCE_FLAG FROM INF_ADDRESS_COPY A INNER JOIN INF_ADDR_REFERENCE_COPY B ON A.BE_ID = B.BE_ID AND A.ADDR_ID = B.ADDR_ID  WHERE ((B.ADDR_REF_ENTITY_ID = 23991064964718  AND B.ADDR_REF_PURPOSE_ID = 10001100113  AND A.EXP_DATE > '01-JAN-00'  AND A.BE_ID = 23 ));
```

平均执行时间约为3ms，对表DDL进行分析：

```plsql
CREATE TABLE "SUBS"."INF_ADDR_REFERENCE" (
    "ADDR_REF_ID" NUMBER(20,0) NOT NULL,
    "ADDR_ID" NUMBER(20,0) NOT NULL,
    "ADDR_REF_PURPOSE_ID" NUMBER(20,0) NOT NULL,
    "ADDR_REF_ENTITY_ID" NUMBER(20,0) NOT NULL,
    "PREFERENCE_FLAG" VARCHAR2(1 BYTE),
    "EFF_DATE" DATE NOT NULL,
    "EXP_DATE" DATE NOT NULL,
    "CREATE_PROLE_TYPE" VARCHAR2(4 BYTE),
    "CREATE_PROLE_ID" NUMBER(20,0),
    "CREATE_DEPT_ID" NUMBER(20,0),
    "CREATE_TIME" DATE,
    "MODIFY_PROLE_TYPE" VARCHAR2(4 BYTE),
    "MODIFY_PROLE_ID" NUMBER(20,0),
    "MODIFY_DEPT_ID" NUMBER(20,0),
    "MODIFY_TIME" DATE,
    "BE_ID" NUMBER(10,0) NOT NULL,
    CONSTRAINT "PK_INF_ADDR_REFERENCE" PRIMARY KEY ("ADDR_REF_ID", "ADDR_REF_ENTITY_ID", "BE_ID")
)
PARTITION BY LIST ("BE_ID")
SUBPARTITION BY HASH ("ADDR_REF_ENTITY_ID")
SUBPARTITIONS 1
(
    PARTITION "P_L_23" VALUES (23)
    (
        SUBPARTITION "P_L_23_H_1",
        SUBPARTITION "P_L_23_H_2",
        SUBPARTITION "P_L_23_H_3",
        SUBPARTITION "P_L_23_H_4",
        SUBPARTITION "P_L_23_H_5",
        SUBPARTITION "P_L_23_H_6",
        SUBPARTITION "P_L_23_H_7",
        SUBPARTITION "P_L_23_H_8",
        SUBPARTITION "P_L_23_H_9",
        SUBPARTITION "P_L_23_H_10",
        SUBPARTITION "P_L_23_H_11",
        SUBPARTITION "P_L_23_H_12",
        SUBPARTITION "P_L_23_H_13",
        SUBPARTITION "P_L_23_H_14",
        SUBPARTITION "P_L_23_H_15",
        SUBPARTITION "P_L_23_H_16",
        SUBPARTITION "P_L_23_H_17",
        SUBPARTITION "P_L_23_H_18",
        SUBPARTITION "P_L_23_H_19",
        SUBPARTITION "P_L_23_H_20",
        SUBPARTITION "P_L_23_H_21",
        SUBPARTITION "P_L_23_H_22",
        SUBPARTITION "P_L_23_H_23",
        SUBPARTITION "P_L_23_H_24",
        SUBPARTITION "P_L_23_H_25",
        SUBPARTITION "P_L_23_H_26",
        SUBPARTITION "P_L_23_H_27",
        SUBPARTITION "P_L_23_H_28",
        SUBPARTITION "P_L_23_H_29",
        SUBPARTITION "P_L_23_H_30",
        SUBPARTITION "P_L_23_H_31",
        SUBPARTITION "P_L_23_H_32"
    )
);
CREATE INDEX "SUBS"."IDX_INF_ADDR_REFERENCE_01" ON "SUBS"."INF_ADDR_REFERENCE" ("ADDR_REF_ENTITY_ID" ASC) LOCAL;
CREATE INDEX "SUBS"."IDX_INF_ADDR_REFERENCE_ATTRID" ON "SUBS"."INF_ADDR_REFERENCE" ("ADDR_ID" ASC) LOCAL;

CREATE TABLE "SUBS"."INF_ADDRESS" (
    "ADDR_ID" NUMBER(20,0) NOT NULL,
    "PARTY_ID" NUMBER(20,0) NOT NULL,
    "PARTY_TYPE" VARCHAR2(4 BYTE) NOT NULL,
    "ADDR_TYPE" VARCHAR2(4 BYTE) NOT NULL,
    "ADDR_1" VARCHAR2(512 BYTE),
    "ADDR_2" VARCHAR2(512 BYTE),
    "ADDR_3" VARCHAR2(512 BYTE),
    "ADDR_4" VARCHAR2(512 BYTE),
    "ADDR_5" VARCHAR2(512 BYTE),
    "ADDR_6" VARCHAR2(512 BYTE),
    "ADDR_7" VARCHAR2(512 BYTE),
    "ADDR_8" VARCHAR2(512 BYTE),
    "ADDR_9" VARCHAR2(512 BYTE),
    "ADDR_10" VARCHAR2(512 BYTE),
    "ADDR_11" VARCHAR2(512 BYTE),
    "ADDR_12" VARCHAR2(512 BYTE),
    "ADDR_13" VARCHAR2(512 BYTE),
    "ADDR_14" VARCHAR2(512 BYTE),
    "ADDR_15" VARCHAR2(512 BYTE),
    "REGION_ID" NUMBER(20,0) NOT NULL,
    "US_ADDR" VARCHAR2(1024 BYTE),
    "ADDR_TEMP_ID" NUMBER(20,0),
    "POSTAL_CODE" VARCHAR2(16 BYTE),
    "DISTRICT_ID" VARCHAR2(32 BYTE),
    "DISTRICT_NAME" VARCHAR2(512 BYTE),
    "EFF_DATE" DATE NOT NULL,
    "EXP_DATE" DATE NOT NULL,
    "CREATE_PROLE_TYPE" VARCHAR2(4 BYTE),
    "CREATE_PROLE_ID" NUMBER(20,0),
    "CREATE_DEPT_ID" NUMBER(20,0),
    "CREATE_TIME" DATE,
    "MODIFY_PROLE_TYPE" VARCHAR2(4 BYTE),
    "MODIFY_PROLE_ID" NUMBER(20,0),
    "MODIFY_DEPT_ID" NUMBER(20,0),
    "MODIFY_TIME" DATE,
    "BE_ID" NUMBER(10,0) NOT NULL,
    CONSTRAINT "PK_INF_ADDRESS" PRIMARY KEY ("ADDR_ID", "PARTY_ID", "BE_ID")
)
PARTITION BY LIST ("BE_ID")
SUBPARTITION BY HASH ("PARTY_ID")
SUBPARTITIONS 1
(
    PARTITION "P_L_23" VALUES (23)
    (
        SUBPARTITION "P_L_23_H_1",
        SUBPARTITION "P_L_23_H_2",
        SUBPARTITION "P_L_23_H_3",
        SUBPARTITION "P_L_23_H_4",
        SUBPARTITION "P_L_23_H_5",
        SUBPARTITION "P_L_23_H_6",
        SUBPARTITION "P_L_23_H_7",
        SUBPARTITION "P_L_23_H_8",
        SUBPARTITION "P_L_23_H_9",
        SUBPARTITION "P_L_23_H_10",
        SUBPARTITION "P_L_23_H_11",
        SUBPARTITION "P_L_23_H_12",
        SUBPARTITION "P_L_23_H_13",
        SUBPARTITION "P_L_23_H_14",
        SUBPARTITION "P_L_23_H_15",
        SUBPARTITION "P_L_23_H_16",
        SUBPARTITION "P_L_23_H_17",
        SUBPARTITION "P_L_23_H_18",
        SUBPARTITION "P_L_23_H_19",
        SUBPARTITION "P_L_23_H_20",
        SUBPARTITION "P_L_23_H_21",
        SUBPARTITION "P_L_23_H_22",
        SUBPARTITION "P_L_23_H_23",
        SUBPARTITION "P_L_23_H_24",
        SUBPARTITION "P_L_23_H_25",
        SUBPARTITION "P_L_23_H_26",
        SUBPARTITION "P_L_23_H_27",
        SUBPARTITION "P_L_23_H_28",
        SUBPARTITION "P_L_23_H_29",
        SUBPARTITION "P_L_23_H_30",
        SUBPARTITION "P_L_23_H_31",
        SUBPARTITION "P_L_23_H_32"
    )
);

CREATE INDEX "SUBS"."IDX_INF_ADDRESS_01" ON "SUBS"."INF_ADDRESS" ("PARTY_ID" ASC) LOCAL;
```

从语句中的条件我们获知，该语句的关联条件是：A.BE_ID = B.BE_ID AND A.ADDR_ID = B.ADDR_ID，即关联条件只使用到了一级分区键值，未使用到二级分区键值，虽然分区的规则一致。

这种情况下考虑2种优化方式，使用tablegroup将2个表进行纳管，虽然是一个分布式计划，但是关联的查询能够在单机上执行，仅需要汇聚结果。

再对数据量进行分析：

```plsql
obclient [SUBS]> select count(*) from INF_ADDR_REFERENCE;
+----------+
| COUNT(*) |
+----------+
|  6007796 |
+----------+
1 row in set (2.038 sec)

obclient [SUBS]> select count(*) from INF_ADDRESS;
+----------+
| COUNT(*) |
+----------+
|  5507551 |
+----------+
1 row in set (1.823 sec)
```

2个表的数据均不足1000w，OceanBase分区的建议是单表超1000w或者100GB的数据使用分区，或者因为运维需求创建分区，从数据量和分区数上来看，分区建设的不合理，仅保留一级分区，修改DDL如下：

```plsql
CREATE TABLE "SUBS"."INF_ADDR_REFERENCE_COPY" (
    "ADDR_REF_ID" NUMBER(20,0) NOT NULL,
    "ADDR_ID" NUMBER(20,0) NOT NULL,
    "ADDR_REF_PURPOSE_ID" NUMBER(20,0) NOT NULL,
    "ADDR_REF_ENTITY_ID" NUMBER(20,0) NOT NULL,
    "PREFERENCE_FLAG" VARCHAR2(1 BYTE),
    "EFF_DATE" DATE NOT NULL,
    "EXP_DATE" DATE NOT NULL,
    "CREATE_PROLE_TYPE" VARCHAR2(4 BYTE),
    "CREATE_PROLE_ID" NUMBER(20,0),
    "CREATE_DEPT_ID" NUMBER(20,0),
    "CREATE_TIME" DATE,
    "MODIFY_PROLE_TYPE" VARCHAR2(4 BYTE),
    "MODIFY_PROLE_ID" NUMBER(20,0),
    "MODIFY_DEPT_ID" NUMBER(20,0),
    "MODIFY_TIME" DATE,
    "BE_ID" NUMBER(10,0) NOT NULL,
    CONSTRAINT "PK_INF_ADDR_REFERENCE_COPY" PRIMARY KEY ("ADDR_REF_ID", "ADDR_REF_ENTITY_ID", "BE_ID")
)
PARTITION BY LIST ("BE_ID")
(
    PARTITION "P_L_23" VALUES (23)
);
CREATE INDEX "SUBS"."IDX_INF_ADDR_REFERENCE_COPY_01" ON "SUBS"."INF_ADDR_REFERENCE_COPY" ("ADDR_REF_ENTITY_ID" ASC) LOCAL;
CREATE INDEX "SUBS"."IDX_INF_ADDR_REFERENCE_ATTRID_COPY" ON "SUBS"."INF_ADDR_REFERENCE_COPY" ("ADDR_ID" ASC) LOCAL;

CREATE TABLE "SUBS"."INF_ADDRESS_COPY" (
    "ADDR_ID" NUMBER(20,0) NOT NULL,
    "PARTY_ID" NUMBER(20,0) NOT NULL,
    "PARTY_TYPE" VARCHAR2(4 BYTE) NOT NULL,
    "ADDR_TYPE" VARCHAR2(4 BYTE) NOT NULL,
    "ADDR_1" VARCHAR2(512 BYTE),
    "ADDR_2" VARCHAR2(512 BYTE),
    "ADDR_3" VARCHAR2(512 BYTE),
    "ADDR_4" VARCHAR2(512 BYTE),
    "ADDR_5" VARCHAR2(512 BYTE),
    "ADDR_6" VARCHAR2(512 BYTE),
    "ADDR_7" VARCHAR2(512 BYTE),
    "ADDR_8" VARCHAR2(512 BYTE),
    "ADDR_9" VARCHAR2(512 BYTE),
    "ADDR_10" VARCHAR2(512 BYTE),
    "ADDR_11" VARCHAR2(512 BYTE),
    "ADDR_12" VARCHAR2(512 BYTE),
    "ADDR_13" VARCHAR2(512 BYTE),
    "ADDR_14" VARCHAR2(512 BYTE),
    "ADDR_15" VARCHAR2(512 BYTE),
    "REGION_ID" NUMBER(20,0) NOT NULL,
    "US_ADDR" VARCHAR2(1024 BYTE),
    "ADDR_TEMP_ID" NUMBER(20,0),
    "POSTAL_CODE" VARCHAR2(16 BYTE),
    "DISTRICT_ID" VARCHAR2(32 BYTE),
    "DISTRICT_NAME" VARCHAR2(512 BYTE),
    "EFF_DATE" DATE NOT NULL,
    "EXP_DATE" DATE NOT NULL,
    "CREATE_PROLE_TYPE" VARCHAR2(4 BYTE),
    "CREATE_PROLE_ID" NUMBER(20,0),
    "CREATE_DEPT_ID" NUMBER(20,0),
    "CREATE_TIME" DATE,
    "MODIFY_PROLE_TYPE" VARCHAR2(4 BYTE),
    "MODIFY_PROLE_ID" NUMBER(20,0),
    "MODIFY_DEPT_ID" NUMBER(20,0),
    "MODIFY_TIME" DATE,
    "BE_ID" NUMBER(10,0) NOT NULL,
    CONSTRAINT "PK_INF_ADDRESS_COPY" PRIMARY KEY ("ADDR_ID", "PARTY_ID", "BE_ID")
)
PARTITION BY LIST ("BE_ID")
(
    PARTITION "P_L_23" VALUES (23)
);

CREATE INDEX "SUBS"."IDX_INF_ADDRESS_COPY_01" ON "SUBS"."INF_ADDRESS_COPY" ("PARTY_ID" ASC) LOCAL;
```

由于2表的分区规则还是一致的，所以可以使用tablegroup进行聚合

```plsql
create tablegroup tg1 PARTITION BY LIST COLUMNS 1(PARTITION "P_L_23" VALUES (23));

ALTER TABLEGROUP tg1 ADD INF_ADDRESS_COPY,INF_ADDR_REFERENCE_COPY;
```

再次进行压测获取结果：

![](/Users/qiyibaba/gitbook/image/2022-10-28-22-30-26-image.png)

性能从2822us提升到了700us，分布式执行的耗时分布主要有：

1. get plan耗时

2. 分布式执行中序列化/反序列化物理执行计划, 序列化/反序列化session, 序列化/反序列化执行上下文

3. 分布式调度初始化

4. 算子的执行

5. RPC通信

本地执行的耗时主要是：

1. get plan耗时

2. 算子执行

整体分布式执行的时间相对于单机来说，多了很多个步骤，相对性的性能也会相差很多所以对于多表关联查询场景考虑优化方式有：

1. 使用tablegroup进行关联

2. 建设合理的分区数：单分区1000w或者100GB数据

3. 表级的聚合

### 单表多分区扫描

> 单表多分区扫描占比21.6%

测试语句如下：

```plsql
select a.APPLY_OBJ_BE_ID, a.APPLY_OBJ_ID, a.APPLY_OBJ_TYPE, a.BE_CODE, a.BE_ID, a.BRAND, a.BUNDLE_FLAG, a.CREATE_DEPT_ID, a.CREATE_ORDER_ID, a.CREATE_PROLE_ID, a.CREATE_PROLE_TYPE, a.CREATE_TIME, a.EFF_DATE, a.EXP_DATE, a.EX_FIELD1, a.EX_FIELD10, a.EX_FIELD12, a.EX_FIELD13, a.EX_FIELD16, a.EX_FIELD17, a.EX_FIELD18, a.EX_FIELD20, a.EX_FIELD14, a.EX_FIELD2, a.EX_FIELD3, a.EX_FIELD4, a.EX_FIELD5, a.EX_FIELD6, a.EX_FIELD7, a.EX_FIELD8, a.EX_FIELD9, a.HIS_DATE, a.LAST_MOD_ORDER_ID, a.MODIFY_CHANNEL_TYPE, a.MODIFY_DEPT_ID, a.MODIFY_PROLE_ID, a.MODIFY_PROLE_TYPE, a.MODIFY_TIME, a.OFFERING_CODE, a.OFFERING_ID, a.OFFERING_INST_ID, a.RELA_OFFERING_INST_ID, a.OFFERING_SUB_TYPE, a.OFFERING_TYPE, a.OWNER_PARTY_ROLE_ID, a.OWNER_PARTY_ROLE_TYPE, a.PRIMARY_FLAG, a.PURCHASE_SEQ, a.P_OFFERING_INST_ID, a.REL_PRI_OFFERING_INST_ID, a.SALES_CHANNEL_ID, a.SALES_CHANNEL_TYPE, a.SALES_ID, a.STATUS, a.STATUS_DATE, a.STATUS_DETAIL, a.SUBS_ID from INF_OFFERING_INST_HIS a  where ((a.SUBS_ID = 2399101309920058  and a.BE_ID = 23 ))
```

DDL信息如下：

```plsql
CREATE TABLE "SUBS"."INF_OFFERING_INST_HIS" (
    "OFFERING_INST_ID" NUMBER(20,0) NOT NULL,
    "SUBS_ID" NUMBER(20,0),
    "OFFERING_ID" NUMBER(20,0) NOT NULL,
    "OFFERING_CODE" VARCHAR2(64 BYTE),
    "OWNER_PARTY_ROLE_TYPE" VARCHAR2(4 BYTE) NOT NULL,
    "OWNER_PARTY_ROLE_ID" NUMBER(20,0) NOT NULL,
    "PURCHASE_SEQ" VARCHAR2(64 BYTE),
    "BRAND" NUMBER(20,0),
    "PRIMARY_FLAG" VARCHAR2(1 BYTE) NOT NULL,
    "REL_PRI_OFFERING_INST_ID" NUMBER(20,0),
    "BUNDLE_FLAG" VARCHAR2(1 BYTE) NOT NULL,
    "P_OFFERING_INST_ID" NUMBER(20,0),
    "APPLY_OBJ_TYPE" VARCHAR2(4 BYTE) NOT NULL,
    "APPLY_OBJ_ID" NUMBER(20,0) NOT NULL,
    "APPLY_OBJ_BE_ID" NUMBER(10,0),
    "OFFERING_TYPE" VARCHAR2(32 BYTE),
    "OFFERING_SUB_TYPE" VARCHAR2(32 BYTE),
    "STATUS" VARCHAR2(1 BYTE) NOT NULL,
    "STATUS_DETAIL" VARCHAR2(16 BYTE),
    "STATUS_DATE" DATE,
    "EFF_DATE" DATE,
    "EXP_DATE" DATE,
    "CREATE_ORDER_ID" NUMBER(20,0),
    "LAST_MOD_ORDER_ID" NUMBER(20,0),
    "SALES_CHANNEL_TYPE" VARCHAR2(4 BYTE),
    "SALES_CHANNEL_ID" VARCHAR2(24 BYTE),
    "SALES_ID" NUMBER(20,0),
    "BE_ID" NUMBER(10,0) NOT NULL,
    "BE_CODE" VARCHAR2(256 BYTE),
    "CREATE_PROLE_TYPE" VARCHAR2(4 BYTE),
    "CREATE_PROLE_ID" NUMBER(20,0),
    "CREATE_DEPT_ID" NUMBER(20,0),
    "CREATE_TIME" DATE,
    "MODIFY_CHANNEL_TYPE" VARCHAR2(4 BYTE),
    "MODIFY_PROLE_TYPE" VARCHAR2(4 BYTE),
    "MODIFY_PROLE_ID" NUMBER(20,0),
    "MODIFY_DEPT_ID" NUMBER(20,0),
    "MODIFY_TIME" DATE,
    "HIS_DATE" DATE NOT NULL,
    "EX_FIELD1" VARCHAR2(32 BYTE),
    "EX_FIELD2" VARCHAR2(32 BYTE),
    "EX_FIELD3" VARCHAR2(32 BYTE),
    "EX_FIELD4" VARCHAR2(32 BYTE),
    "EX_FIELD5" VARCHAR2(32 BYTE),
    "EX_FIELD6" VARCHAR2(32 BYTE),
    "EX_FIELD7" VARCHAR2(32 BYTE),
    "EX_FIELD8" VARCHAR2(32 BYTE),
    "EX_FIELD9" VARCHAR2(32 BYTE),
    "EX_FIELD10" VARCHAR2(32 BYTE),
    "EX_FIELD11" VARCHAR2(32 BYTE),
    "EX_FIELD12" VARCHAR2(32 BYTE),
    "EX_FIELD13" VARCHAR2(32 BYTE),
    "EX_FIELD14" VARCHAR2(32 BYTE),
    "EX_FIELD15" VARCHAR2(32 BYTE),
    "EX_FIELD16" VARCHAR2(32 BYTE),
    "EX_FIELD17" VARCHAR2(32 BYTE),
    "EX_FIELD18" VARCHAR2(32 BYTE),
    "EX_FIELD19" VARCHAR2(32 BYTE),
    "EX_FIELD20" VARCHAR2(32 BYTE),
    "RELA_OFFERING_INST_ID" NUMBER(20,0),
    CONSTRAINT "PK_INF_OFFERING_INST_HIS" PRIMARY KEY ("OFFERING_INST_ID", "BE_ID", "HIS_DATE")
)
PARTITION BY RANGE ("HIS_DATE")
SUBPARTITION BY LIST ("BE_ID")
SUBPARTITION TEMPLATE
(
    SUBPARTITION "L_23" VALUES (23)
)
(
    PARTITION "P_R_202206" VALUES LESS THAN (TO_DATE(' 2022-07-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN')),
    PARTITION "P_R_202207" VALUES LESS THAN (TO_DATE(' 2022-08-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN')),
    PARTITION "P_R_202208" VALUES LESS THAN (TO_DATE(' 2022-09-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN')),
    PARTITION "P_R_202209" VALUES LESS THAN (TO_DATE(' 2022-10-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN')),
    PARTITION "P_R_PMAX" VALUES LESS THAN (TO_DATE(' 2037-01-01 00:00:00', 'SYYYY-MM-DD HH24:MI:SS', 'NLS_CALENDAR=GREGORIAN'))
);
```

该表由于运维需求，使用了HIS_DATE时间的一级分区，然后使用BE_ID作为二级分区。在查询的过程中，仅使用二级分区键值，不使用一级分区键值。

OceanBase是对每个一级分区作为1个负载均衡组，所以每个一级分区下面的所有二级分区会被打散，一级分区不控制，所以建议设置一级分区为时间，二级分区为BE_ID，这样不会破坏负载均衡策略，同时进行手工运维后也不会被重新打散。

进行性能压测获取结果：

```plsql
obclient [oceanbase]> select svr_ip,avg(ELAPSED_TIME),count(*),sql_id,plan_type from gv$sql_audit where sql_id='2F95DA76B6EDECCF828FF282D9600B18' group by svr_ip;
+---------------+-------------------+----------+----------------------------------+-----------+
| svr_ip        | avg(ELAPSED_TIME) | count(*) | sql_id                           | plan_type |
+---------------+-------------------+----------+----------------------------------+-----------+
| 10.33.221.184 |         1778.4180 |     1000 | 2F95DA76B6EDECCF828FF282D9600B18 |         3 |
+---------------+-------------------+----------+----------------------------------+-----------+
1 row in set (0.030 sec)
```

平均执行时间为1778us，分析该表的所有分区leader分布：

![](/Users/qiyibaba/gitbook/image/2022-10-27-06-40-00-image.png)

分区leader分布在183和184机器上，进行手工搬迁：

![](/Users/qiyibaba/gitbook/image/2022-10-27-06-38-46-image.png)

搬迁完成后进行leader分布验证：

![](/Users/qiyibaba/gitbook/image/2022-10-27-06-39-27-image.png)

再次进行性能压测：

```plsql
obclient [oceanbase]> select svr_ip,avg(ELAPSED_TIME),count(*),sql_id,plan_type from gv$sql_audit where sql_id='2F95DA76B6EDECCF828FF282D9600B18' group by svr_ip;
+---------------+-------------------+----------+----------------------------------+-----------+
| svr_ip        | avg(ELAPSED_TIME) | count(*) | sql_id                           | plan_type |
+---------------+-------------------+----------+----------------------------------+-----------+
| 10.33.221.184 |         1598.8990 |     1000 | 2F95DA76B6EDECCF828FF282D9600B18 |         3 |
+---------------+-------------------+----------+----------------------------------+-----------+
1 row in set (0.030 sec)
```

性能从1778us提升到了1598us。

```
多机RT = 扫描数据总耗时/机器个数 +  (1 + 返回包拆分64K包个数) * 服务器延时
单机RT = 扫描数据总耗时
```

多机相对于单机而言，存在多次的网络的发包，同时也会带来扫描的性能提升。但是对于扫描返回数据量小于64K数据时，多机的性能会比单机长大概2个RPC的网络时间。

对于单表多分区场景，优化建议如下：

1. 一级分区为时间，二级分区为BE_ID，这样不会破坏负载均衡策略，同时进行手工运维后也不会被重新打散

2. 使用手工方式进行人工运维

3. OceanBase支持表级的聚合功能（4.2支持）

# XA事务的优化

## 改造成普通事务

![](/Users/qiyibaba/gitbook/image/2022-10-27-06-45-09-image.png)

1. 从事务统计信息上看，发起XA事务到真正执行业务语句中间有4ms的时间，建议去除XA事务

2. XA事务会影响路由的准确性，所以从精准路由方面也考虑去除XA

3. XA事务具备一定的特殊性，XA事务需要进行所有OceanBase节点的同步，所以在分布式的场景下，分布式节点越多，XA START的耗时就越长，从分布式扩容的角度考虑，也建议尽量少用XA

## 去除XA SET TIMTOUT

xa协议中未定义xa事务超时时间。而在Oracle实现中，为避免xa分支挂起后各种异常导致事务长时间持有资源的情况，引入了xa事务超时时间。具体可参考文档：https://docs.oracle.com/database/121/ARPLS/d_xa.htm#ARPLS209

在Oracle中，可通过执行xa_settimeout来设置xa事务的超时时间。该超时时间主要用于避免xa事务分支长时间被挂起。具体来说，当一个事务分支被挂起后（成功执行完xa end），在超时时间内，如果该事务分支没有收到后续的xa事务请求，则该事务分支被认为超时。当事务分支超时之后，资源管理器可以主动回滚该事务。在Oracle数据库中，该超时时间的默认值为60秒。

### 行为验证

主要验证：在Oracle数据中，xa_settimeout对xa事务分支的影响。

2.1 场景一：默认60秒

> xa_start(g1b1, noflags)
> 0
> sql1
> sleep 80
> sql2
> xa_end(g1b1)
> 0
> sleep 80
> xa_start(g1b1, join)
> -4

通过以上执行可以发现，如果xa事务分支处于活跃状态（成功执行完xa start），则xa事务超时时间不会对该事务分支产生影响。也就是说，处于活跃状态的事务分支，如果其执行时间超过xa事务超时时间，该事务分支也不会被回滚。

在执行示例中，由于没有设置xa事务超时时间，因此，xa事务开启后超时时间为默认60秒。因此，当事务分支被挂起后（成功执行完xa end），等待80秒后，由于该事务分支被回滚，后续再继续执行针对该事务分支对应xa语句请求的时候返回错误码-4（XID无效）。

2.2 场景二：事务开启前设置超时时间为120秒

> xa_settimeout(120)
> xa_start(g1b1, noflags)
> 0
> sql1
> xa_end(g1b1)
> 0
> sleep 80
> xa_start(g1b1, join)
> 0

在开启xa事务前设置xa事务超时时间，则该超时时间将影响该事务。如执行示例所示，事务开启前，设置xa事务超时时间为120秒，因此，当该事务分支被挂起后，等待80秒之后，该事务分支未超时。

2.3 场景三：事务开启后设置超时时间为120秒

> xa_start(g1b1, noflags)
> 0
> xa_settimeout(120)
> sql1
> xa_end(g1b1)
> 0
> sleep 80
> xa_start(g1b1, join)
> -4

在开启xa事务后设置xa事务超时时间，则该超时时间不影响该事务。如执行示例所示，事务开启后，设置xa事务超时时间为120秒，因此，当该事务分支被挂起后，等待80秒之后，该事务分支超时，后续再针对该事务分支执行xa语句请求的时候返回错误码-4（XID无效）。

2.4 场景四：tuxedo

在tuxedo中，xa事务超时时间配置在UBBCONFIG文件中。tuxedo在创建完会话后，会在新建会话上执行一次xa_settimeout，将xa事务超时时间设置在会话变量上。在该会话上，后续开启的xa事务将直接获取会话上的变量来作为自己的xa事务超时时间。因此，在xa事务执行过程中，不会再次调用xa_setimeout。

### 使用建议

1. 由于事务中xa_settimeout并不会对当前事务生效，去除xa_settimeout

2. 如果必要，在session级别设置xa_settimeout
